{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600c56ac-7588-4506-bad1-16ea70779c73",
   "metadata": {},
   "source": [
    "\n",
    "# üß† What is Inference in AI?\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Definition\n",
    "\n",
    "**Inference** = The moment when an AI model uses what it *already knows* (its trained knowledge)  \n",
    "to **make a prediction**, **generate text**, **create an image**, or **answer a question**.\n",
    "\n",
    "‚úÖ No learning or retraining happening ‚Äî  \n",
    "‚úÖ Just **using** the model to **do something useful**.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Inference vs Training\n",
    "\n",
    "| Phase | What Happens |\n",
    "|:---|:---|\n",
    "| **Training** | Model *learns* patterns from huge datasets (very slow, very expensive) |\n",
    "| **Inference** | Model *uses* its learning to generate outputs (very fast, very cheap) |\n",
    "\n",
    "‚úÖ Inference = \"brain at work\"  \n",
    "‚úÖ Training = \"brain growing and learning\"\n",
    "\n",
    "---\n",
    "\n",
    "## üî• Real Examples of Inference\n",
    "\n",
    "| Example | What's Happening |\n",
    "|:---|:---|\n",
    "| **Chatbot answering you** | Inference happening at every reply |\n",
    "| **Image generator creating a painting** | Inference from your text prompt |\n",
    "| **Voice AI reading text out loud** | Inference to turn text ‚ûî speech |\n",
    "| **Recommendation engines** | Inference to guess what you might like |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Why Inference Matters\n",
    "\n",
    "- It's what makes AI **useful** in real-world apps\n",
    "- It's **much cheaper** and **faster** than training\n",
    "- It lets you **reuse** powerful models without building your own\n",
    "\n",
    "‚úÖ Training a model might take *weeks*  \n",
    "‚úÖ Inference usually takes *seconds*\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Inference in Code (Example)\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a ready-to-go model for sentiment analysis\n",
    "analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Use (infer) on new data\n",
    "result = analyzer(\"I love learning AI!\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "- No retraining needed\n",
    "- Instant answer\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Final Thought\n",
    "\n",
    "> **Training is hard. Inference is magic.**\n",
    "\n",
    "When you run inference, you‚Äôre putting the model‚Äôs superpowers to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f40ca73-9a24-4de2-b9ab-07ce26d80d64",
   "metadata": {},
   "source": [
    "\n",
    "# üöÄ Must-Know AI Buzzwords for AI beginners\n",
    "\n",
    "---\n",
    "<img src=\"../buzz.png\" width=\"500\" height=\"500\"/>\n",
    "## üî• Core Buzzwords\n",
    "\n",
    "| Buzzword | Meaning |\n",
    "|:---|:---|\n",
    "| **Training** | Teaching a model by feeding it tons of data |\n",
    "| **Inference** | Using a trained model to make predictions |\n",
    "| **Fine-tuning** | Re-training a model on new, smaller data to specialize it |\n",
    "| **Parameters** | The \"knobs\" inside a model that get adjusted during training |\n",
    "| **Tokens** | Tiny pieces of input text a model reads (words, chunks, or characters) |\n",
    "| **Context Window** | The maximum number of tokens a model can remember at once |\n",
    "| **Zero-shot** | Asking a model to solve a task without giving examples |\n",
    "| **Few-shot** | Giving a model a few examples before asking it to solve a task |\n",
    "| **Prompt Engineering** | Crafting clever prompts to get better model answers |\n",
    "| **Multimodal** | Models that handle **more than one type of input** (text + image, etc.) |\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è More Advanced (but Fun to Know)\n",
    "\n",
    "| Buzzword | Meaning |\n",
    "|:---|:---|\n",
    "| **Embedding** | Turning text into numbers (vectors) for search or matching |\n",
    "| **RAG (Retrieval Augmented Generation)** | Mixing search + generation for better answers |\n",
    "| **LoRA (Low-Rank Adaptation)** | A clever way to fine-tune giant models without huge costs |\n",
    "| **Supervised Fine-Tuning (SFT)** | Training models on human-checked examples |\n",
    "| **Reinforcement Learning with Human Feedback (RLHF)** | Making AIs better by rewarding good answers |\n",
    "| **Mixture of Experts (MoE)** | Only activating parts of a huge model depending on the task |\n",
    "| **Diffusion Models** | New models that create images (like Stable Diffusion) |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Tiny Motivation\n",
    "\n",
    "> **Knowing these words = speaking the secret language of AI engineers.**  \n",
    "> It's like learning wizard spells for machine learning! üßô‚Äç‚ôÇÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae93669-79f0-4487-a519-dc60488c4a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
