{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc19241b-44bd-456b-a9cf-c501c612a40a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸ—£ï¸ Build a \"Talk-to-Me\" Conversationalist Chatbot\n",
    "\n",
    "<img src=\"../talk_talk.png\" width=\"400\" height=\"400\"/>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ What's This About?\n",
    "\n",
    "Not all chatbots are goldfish. ğŸŸ  \n",
    "Some actually **remember** what you said 10 seconds ago!  \n",
    "Welcome to the world of **conversationalist chatbots** â€” where bots keep the story going, one prompt at a time.\n",
    "\n",
    "In this lab, you'll build a chatbot that:\n",
    "\n",
    "- **Remembers your previous questions**\n",
    "- **Responds with context** (so it doesnâ€™t say \"Who are you?\" every two seconds)\n",
    "- **Feels more like a conversation, less like yelling into the void**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ How It Works\n",
    "\n",
    "| Part | Whatâ€™s Happening |\n",
    "|:---|:---|\n",
    "| Message List | Every user message and bot response gets saved |\n",
    "| Full History | Each new call sends **all** past messages again |\n",
    "| AI Thinks | Based on the *entire conversation*, not just the latest input |\n",
    "\n",
    "âœ… The AIâ€™s brain:  \n",
    "- First, it knew nothing.  \n",
    "- Now, itâ€™s slowly piecing your weird conversation together.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Why This Matters\n",
    "\n",
    "- **Memory makes magic.**  \n",
    "Without context, your chatbot is just a parrot.  \n",
    "With memory, it becomes a guide, a friend, a co-pilot.\n",
    "\n",
    "- **Real apps** (like ChatGPT, Claude, Gemini) all work this way under the hood.  \n",
    "They just *fake* long-term memory by *replaying* everything each time.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ¯ Your Goal\n",
    "\n",
    "Build a **talk-to-me chatbot** that:\n",
    "\n",
    "- Keeps the chat history growing  \n",
    "- Responds like it knows whatâ€™s going on  \n",
    "- Feels more like a conversation, less like a quiz\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ Final Thought\n",
    "\n",
    "> **Today: Your chatbot remembers a few lines.  \n",
    "> Tomorrow: It remembers your life story.** Muhahaha :wink:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b427253-b532-4cf8-a10c-a2ea58440548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d722c-eedf-4f41-9d12-b8190aa5c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf117f1-2a92-4fb8-b24a-afe467ac3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "openai = OpenAI()\n",
    "MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa070385-f767-470a-9426-73bacd1eb909",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b45d34-962d-4162-a990-140e041d8544",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ› ï¸ Gradioâ€™s Hidden Superpower: Sending Conversation History in OpenAI Format\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Whatâ€™s the Big Deal?\n",
    "\n",
    "Gradio makes it incredibly easy to **build chatbots that remember conversations**.  \n",
    "But the best part?  \n",
    "It **automatically stores history** in the **exact format OpenAI models expect** â€” no extra work needed.\n",
    "\n",
    "âœ… That means you can **pass the history directly to OpenAI**, Claude, Gemini, or any model that expects this structure:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\"role\": \"system\", \"content\": \"Set the scene for the AI.\"},\n",
    "  {\"role\": \"user\", \"content\": \"User says something.\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"AI responds.\"},\n",
    "  {\"role\": \"user\", \"content\": \"User says something else.\"},\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Why Is This Awesome?\n",
    "\n",
    "| Feature | Why Itâ€™s Great |\n",
    "|:---|:---|\n",
    "| Auto-history tracking | You donâ€™t have to manually build message lists |\n",
    "| OpenAI-ready format | Works instantly with GPT, Claude, Gemini APIs |\n",
    "| Clean & scalable | Supports long, multi-turn conversations easily |\n",
    "| Simple inputs | Gradio automatically sends full history back to your `fn` function |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¥ How It Works Under the Hood\n",
    "\n",
    "- Gradio **remembers** all user messages and assistant responses.\n",
    "- Each time the user sends a new message, **Gradio passes the *full* conversation history** into your Python function.\n",
    "- All you need to do is **accept `messages` as an input**, and you get the ready-to-send list!\n",
    "\n",
    "âœ… No history stitching.  \n",
    "âœ… No manual appending.  \n",
    "âœ… No headaches.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ¯ Final Thought\n",
    "\n",
    "> **With Gradio, youâ€™re always one line away from a production-ready conversational AI.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e5704-a172-42eb-8efa-975e2757febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bcd225-dd26-45f9-b37a-e00498e5d02e",
   "metadata": {},
   "source": [
    "## And then enter Gradio's magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34e62b-4377-44f6-90ee-54bc338d4f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261d076e-fc64-408e-bf8b-e32c9aa72058",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant in a AutoBody shop. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. wiper fluid and tires are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer says 'I'm looking to buy a hat', \\\n",
    "you could reply something like, 'Wonderful - we have lots of wiper fluid - including several that are part of our sales event.'\\\n",
    "Encourage the customer to buy tires if they are unsure what to get.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df34874-393a-49dd-9929-6e901c1ac549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28c4f1-1c6a-42c4-8f1f-d615196a4d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8621ad7-ed4d-4711-b9e8-1f8c8d342e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\nIf the customer asks for brake shoes, you should respond that break shoes are not on sale today, \\\n",
    "but remind the customer to look at tires and wiper fluid!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d02b5-6037-479e-9bb5-b5d26db314cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395c8a2-9866-4a59-b8b5-e08a4a42eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "\n",
    "    relevant_system_message = system_message\n",
    "    if 'belt' in message:\n",
    "        relevant_system_message += \" The shope does not sell engine oil; if you are asked for engine oil, be sure to point out other items on sale.\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee9bd3-2779-4269-acdb-3112b15aa0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a722e7f-d5c5-404c-ae7b-9077ab8fc9cb",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸ¦ Lab: The Ice Cream Chatbot (and Licorice Conspiracy)\n",
    "\n",
    "---\n",
    "\n",
    "Build a chatbot for an ice cream store that politely but relentlessly reminds users that **licorice ice cream is 90% off**. When a user asks about flavors, the bot should list them normally (chocolate, vanilla, strawberry, etc.) â€” but always slip in a little \"P.S. Licorice is basically free today!\" somewhere in the response. Keep the bot friendly, helpful, and mildly obsessed with getting rid of licorice.\n",
    "\n",
    "Think about how you'd sneak this into **every answer** without sounding like a broken record â€” and how a real conversational assistant can balance **information + subtle persuasion**. Bonus points if the bot gets *even more desperate* if the user keeps ignoring the deal!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c57f9f-cd8f-4799-85be-10ff19ec0111",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸ† ğŸ® Achievement Unlocked: \"Keeper of Context\" Badge\n",
    "\n",
    "```\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ğŸ¯ Mission Complete: Built a Conversationalist Bot!\n",
    "\n",
    "ğŸ§  New Powers Gained:\n",
    "- Memory unlocked: No more goldfish-mode chats\n",
    "- Context awareness: Your bot actually knows whatâ€™s going on\n",
    "- Real conversation flow: Less \"Who dis?\", more \"Let's continue!\"\n",
    "\n",
    "ğŸ… New Title: Context Commander\n",
    "\n",
    "ğŸš€ Next Quest: Handle *long* conversations without losing your mind (or your tokens)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548e320-591e-4fef-b4f7-5b0afef29a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
