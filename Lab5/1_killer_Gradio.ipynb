{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feedb280-c22b-4f4f-9ec9-2b01782aaf46",
   "metadata": {},
   "source": [
    "# Gradio killed the terminal star\n",
    "---\n",
    "\n",
    "## üéõÔ∏è Gradio: A Quick Overview\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ What is Gradio?\n",
    "\n",
    "- **Gradio** is an open-source Python library that lets you **quickly build simple web apps** for your machine learning models.\n",
    "- It creates **easy-to-use interfaces** where users can interact with your AI by uploading files, typing text, clicking buttons, and more ‚Äî all with **minimal code**.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Why Use Gradio?\n",
    "\n",
    "- **Fast setup** ‚Äî from model to demo in minutes üöÄ\n",
    "- **No frontend skills needed** ‚Äî Gradio handles it for you üé®\n",
    "- **Great for sharing** ‚Äî easy to deploy locally or share online üåê\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú® Key Features\n",
    "\n",
    "| Feature | Description |\n",
    "|:---|:---|\n",
    "| Quick UI for any model | Text, images, audio, video support |\n",
    "| Launch locally or share via link | Instant public links available |\n",
    "| Highly customizable | Choose layouts, themes, components |\n",
    "| Integration ready | Hugging Face, OpenAI, and more |\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Basic Example\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\").launch()\n",
    "```\n",
    "\n",
    "‚úÖ In just a few lines, you have a full working web app!\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ TL;DR\n",
    "\n",
    "> **Gradio makes it ridiculously easy to turn your models into real apps.** üöÄüéõÔ∏è\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Ready to build. ‚úÖ Ready to share. ‚úÖ Ready to shine!\n",
    "\n",
    "---\n",
    "\n",
    "\"Build AI apps instantly. No stress. No frontend. Just magic.\" ‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a1499b-543b-4517-bed2-7f833c5e9c76",
   "metadata": {},
   "source": [
    "### Get ready for some magic! ‚ú®\n",
    "_Your Gradio screens may shine in dark or light mode ‚Äî depending on your computer settings._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10248046-2be6-4af0-80c5-f85c54a387a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3c77b-84a7-4dda-8d58-40112bb2bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr # bow chik bow wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749eeef9-71e4-46f8-9d3f-a4db19f248ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825aa537-d04b-41c5-a450-c704627332f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic and Google; comment out the Claude or Google lines if you're not using them\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9b713-a597-409d-85de-60236cb5de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A generic system message - no more snarky adversarial AIs!\n",
    "\n",
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6434d0e-ce5d-4f52-8452-cc9a717b4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's wrap a call to GPT-4o-mini in a simple function\n",
    "\n",
    "def message_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    completion = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d05746-0339-43f0-9fa7-90444e8b5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can reveal the \"training cut off\", or the most recent date in the training data\n",
    "\n",
    "message_gpt(\"What is today's date?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e41a0b-c131-449f-bd26-0881c9519d6b",
   "metadata": {},
   "source": [
    "# Lift off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d801f27-0d7f-482f-bce3-cf8a61d9d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's an ez function\n",
    "\n",
    "def shout(text):\n",
    "    print(f\"Shout has been called with input {text}\")\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf5bb4-319c-460c-aa84-9d3f1213f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "shout(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93800528-fc07-4eb6-b34b-f1e6ffb90681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The elegance of Gradio. See it in \"light mode\" now ‚Äì a dark mode reveal is coming.\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb767e-4acc-4451-8025-57aec8d70302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simplicity of sharing: share=True provides a public link to your application.\n",
    "# Building on this, we'll introduce Hugging Face Spaces next week for more stable and long-term hosting.\n",
    "\n",
    "# Caution: Using share=True might trigger warnings from some antivirus software or be restricted by corporate firewalls. \n",
    "# If you're currently on a work network, it's recommended to bypass this sharing step.\n",
    "# for GuestBYOD we can try (I guess)\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036889d-d30f-4791-9402-ef6a068e8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding inbrowser=True opens up a new browser window automatically\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7d133-6062-487f-9494-ce3de4e6a373",
   "metadata": {},
   "source": [
    "### Dark Side Temptation (Forcing Dark Mode)\n",
    "\n",
    "Gradio usually dresses up in whatever theme your computer/browser is wearing (light or dark). It's polite like that.\n",
    "\n",
    "You *can* make it wear all black if you're feeling edgy, but Gradio thinks that's kinda bossy (accessibility, you know?).\n",
    "\n",
    "Still wanna force the darkness? Fine, here's the secret handshake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd681e8-4383-4ebd-b982-0b3abc2a72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define this variable and then pass js=force_dark_mode when creating the Interface\n",
    "\n",
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\", js=force_dark_mode).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c2132-79e3-4af1-abbc-c323f45b5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs and Outputs\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=shout,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs=[gr.Textbox(label=\"Response:\", lines=8)],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131242f9-cca3-4c26-ba75-a62ab321b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - changing the function from \"shout\" to \"message_gpt\"\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs=[gr.Textbox(label=\"Response:\", lines=8)],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e535f6e-9859-4535-9314-749b84f18a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù Let's get fancy with Markdown!\n",
    "# Wondering why we set system_message even though it looks unused? \n",
    "# It's secretly global (shhh ü§´) ‚Äî the message_gpt function grabs it behind the scenes!\n",
    "# \n",
    "# Not the cleanest coding move... but hey, it's Jupyter Lab ‚Äî chaos is part of the charm. üòé\n",
    "\n",
    "system_message = \"You are a helpful assistant that responds in markdown\"\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5c9c8-9b31-4fb5-a464-8a3253114378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåä Streaming GPT responses in real-time!\n",
    "# \n",
    "# Need a quick memory jog on \"yield\" and Generators? üß†‚ú®\n",
    "# Check out the Intermediate Python notebook hiding in the week1 folder. üìö\n",
    "\n",
    "def stream_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7c9e9-c690-45fc-bdcc-4f3d54295354",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_gpt,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32084363-a00b-4819-9140-4236213749cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_claude(prompt):\n",
    "    result = claude.messages.stream(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        system=system_message,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    response = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            response += text or \"\"\n",
    "            yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5deec5-1479-4770-ac8c-5c1d1e871a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_claude,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875265df-a2d6-42fc-b9bc-0434219f0ff3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üõ†Ô∏è Minor Upgrade: Python Magic Edition\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What Changed?\n",
    "\n",
    "- Old way:\n",
    "\n",
    "```python\n",
    "for chunk in result:\n",
    "    yield chunk\n",
    "```\n",
    "\n",
    "- New, **fancier** way:\n",
    "\n",
    "```python\n",
    "yield from result\n",
    "```\n",
    "\n",
    "‚úÖ Same result, **way cooler**. Python folks call this \"more Pythonic.\" üêç‚ú®\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Want to Nerd Out More?\n",
    "\n",
    "Need a Python refresher? https://www.youtube.com/watch?v=t8pPdKYpowI if you want to dive deeper into the magic behind `yield from`.\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ TL;DR\n",
    "\n",
    "> **One line. Same power. More style.** üé©üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd05f7a-a01f-4f84-ba6c-350b89eff360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f74795-6dc4-474d-aa3c-1494a7b022bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_model,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\"), gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8dec89-da22-4e40-9477-a61b8a74ff69",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# üèÖ **üéÆ Achievement Unlocked: Gradio Gladiator!**\n",
    "\n",
    "```\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "üèÜ Mission Complete: First Gradio App Built!\n",
    "\n",
    "üéñÔ∏è New Title Earned: \"Interface Alchemist\" üß™\n",
    "\n",
    "‚ú® Skills Gained:\n",
    "- Summoned UIs from pure Python üîÆ\n",
    "- Built, launched, and ruled the frontend kingdom üè∞\n",
    "\n",
    "üöÄ Next Quest: Build smarter, faster, cooler AI experiences!\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
